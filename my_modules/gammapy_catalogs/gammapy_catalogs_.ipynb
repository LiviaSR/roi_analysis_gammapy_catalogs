{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92186057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "path_my_modules = \"/home/born-again/Documents/GitHub/CTA_projects/my_modules\"\n",
    "module_path = os.path.abspath(f'{path_my_modules}/config')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import cfg\n",
    "importlib.reload(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633fb761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cfg' from '/home/born-again/Documents/GitHub/CTA_projects/my_modules/config/cfg.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_path = os.path.abspath(f'{path_my_modules}/{cfg.dir_spectral_models}')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import spectral_models as spec\n",
    "importlib.reload(spec)\n",
    "\n",
    "module_path = os.path.abspath(f'{path_my_modules}/{cfg.dir_utilities}')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utilities as utl\n",
    "importlib.reload(utl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7278b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(f'{path_my_modules}/{cfg.dir_hawc_analysis}')\n",
    "if module_path not in sys.path:\n",
    "    print(sys.path.append(module_path))\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import hawc_analysis as hawc\n",
    "importlib.reload(hawc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(f'{path_my_modules}/{cfg.dir_lhaaso_analysis}')\n",
    "if module_path not in sys.path:\n",
    "    print(sys.path.append(module_path))\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import lhaaso_analysis as lhaaso\n",
    "importlib.reload(lhaaso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba420c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(f'{path_my_modules}/{cfg.dir_hess_analysis}')\n",
    "if module_path not in sys.path:\n",
    "    print(sys.path.append(module_path))\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import hess_analysis as hess\n",
    "importlib.reload(hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4131dfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/born-again/Documents/GitHub/ROI_analysis_gammapy_catalogs/my_modules/LHAASO/my_modules/spectral_models'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_datasets_flux_points_outside_gammapy(region_of_interest):\n",
    "    '''\n",
    "    Select a catalog subset (only sources within a region of interest)\n",
    "    '''\n",
    "    path_datasets = utl.get_path_datasets(region_of_interest)\n",
    "    \n",
    "    datasets_counterparts = Datasets() # global datasets object\n",
    "    models_counterparts = Models()  # global models object\n",
    "    souces_names = []\n",
    "    n_counterparts = 0 # number of counterparts\n",
    "    n_flux_points = 0 # number of flux points tables\n",
    "    \n",
    "    e_ref_min = region_of_interest[\"e_ref_min\"] \n",
    "    e_ref_max = region_of_interest[\"e_ref_max\"]\n",
    "    \n",
    "    roi_pos = region_of_interest[\"position\"]\n",
    "    radius_roi = region_of_interest[\"radius_roi\"]\n",
    "\n",
    "    dict_HAWC = hawc.get_dict()\n",
    "    dict_LHAASO = lhaaso.get_dict()\n",
    "    for index, source_name in enumerate(list(dict_HAWC.keys())):\n",
    "        source_pos = dict_HAWC[source_name][\"position\"]\n",
    "        if roi_pos.separation(source_pos) <= radius_roi:\n",
    "            ds = hawc.get_dataset(source_name)\n",
    "            if any([e_ref_min !=  None, e_ref_max !=  None]):\n",
    "                    ds = cut_flux_points_energy_range(ds, e_ref_min, e_ref_max)\n",
    "            souces_names.append(source_name)        \n",
    "            counterpart_model = ds.models[0]\n",
    "            models_counterparts.append(counterpart_model)\n",
    "            datasets_counterparts.append(ds)\n",
    "            \n",
    "            n_flux_points+=1\n",
    "            n_counterparts+=1 \n",
    "            \n",
    "    for index, source_name in enumerate(list(dict_LHAASO.keys())):\n",
    "        source_pos = dict_LHAASO[source_name][\"position\"]\n",
    "        if roi_pos.separation(source_pos) <= radius_roi:\n",
    "            ds = lhaaso.get_dataset(source_name)\n",
    "            if any([e_ref_min !=  None, e_ref_max !=  None]):\n",
    "                    ds = cut_flux_points_energy_range(ds, e_ref_min, e_ref_max)\n",
    "            souces_names.append(source_name) \n",
    "            counterpart_model = ds.models[0]\n",
    "            models_counterparts.append(counterpart_model)\n",
    "            datasets_counterparts.append(ds)\n",
    "\n",
    "            n_flux_points+=1\n",
    "            n_counterparts+=1\n",
    "            \n",
    "    if datasets_counterparts:\n",
    "        datasets_counterparts.models = models_counterparts\n",
    "        # To save datasets and models\n",
    "        utl.write_datasets_models(datasets_counterparts,region_of_interest, \"counterparts_outside_gammapy\")\n",
    "            \n",
    "        print(f\"Total number of counterparts: {n_counterparts}\")\n",
    "        print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "    \n",
    "        return souces_names, datasets_counterparts, models_counterparts\n",
    "    else: print(\"No counterparts in the ROI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af00140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gammapy.estimators import FluxPoints\n",
    "\n",
    "def cut_flux_points_energy_range(dataset, e_ref_min, e_ref_max):\n",
    "    \n",
    "    if all([e_ref_min ==  None, e_ref_max ==  None]):\n",
    "            raise Exception(f\"Sorry, there is a error: e_ref_min is None and e_ref_max is None)\") \n",
    "    \n",
    "    flux_points = dataset.data\n",
    "    models = dataset.models[0]      \n",
    "    ds_name = dataset.name\n",
    "    \n",
    "    if e_ref_min != None:\n",
    "        mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "        for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "            if e_ref >= e_ref_min:\n",
    "                mask_energy[m] = True\n",
    "\n",
    "        flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "        flux_points = FluxPoints.from_table(flux_points_mask)\n",
    "    \n",
    "    if e_ref_max != None:\n",
    "        mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "        for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "            if e_ref <= e_ref_max:\n",
    "                mask_energy[m] = True\n",
    "\n",
    "        flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "        flux_points = FluxPoints.from_table(flux_points_mask)     \n",
    "        \n",
    "    return FluxPointsDataset(models = models, data = flux_points, name = ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gammapy.datasets import FluxPointsDataset\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "import pickle\n",
    "\n",
    "def create_catalogs_region_of_interest(region_of_interest):\n",
    "    \"\"\"\n",
    "    Gets catalogs subset (only sources within the radius of the region of interest)\n",
    "    \"\"\"\n",
    "    \n",
    "    source_catalogs = utl.load_catalogs_from_gammapy()\n",
    "    \n",
    "    source_position = region_of_interest[\"position\"] \n",
    "    radius_roi = region_of_interest[\"radius_roi\"] \n",
    "        \n",
    "    catalogs_roi = []\n",
    "    catalogs_no_counterparts = []\n",
    "    numbers_catalogs_roi = 0\n",
    "    \n",
    "    for catalog in source_catalogs:        \n",
    "        # Selects only sources within the region of interest. \n",
    "        mask_roi = source_position.separation(catalog.positions) < radius_roi \n",
    "        \n",
    "        if len(catalog[mask_roi].table):\n",
    "            catalogs_roi.append(catalog[mask_roi])\n",
    "            numbers_catalogs_roi += 1\n",
    "        else:\n",
    "            catalogs_no_counterparts.append(f\"{catalog.tag}: {catalog.description}\")\n",
    "    \n",
    "            \n",
    "    if numbers_catalogs_roi:\n",
    "        utl.pickling_catalog_roi(catalogs_roi, region_of_interest)\n",
    "        print(f\"\\n{numbers_catalogs_roi} catalogs with sources within the region of interest:\", end = \"\\n\\n\")\n",
    "        for catalog in catalogs_roi:\n",
    "            print(f\"{catalog.tag}: {catalog.description}\")\n",
    "            display(catalog.table)\n",
    "    else:\n",
    "        print(\"No catalogs with sources in the region of interest!\", end = \"\\n\\n\")\n",
    "\n",
    "    if numbers_catalogs_roi and len(catalogs_no_counterparts):\n",
    "        print(\"Catalogs without sources within the region of interest:\", end = \"\\n\\n\")\n",
    "        for index, catalog_no_counterpart in enumerate(catalogs_no_counterparts):                            \n",
    "            print(catalog_no_counterpart)\n",
    "\n",
    "    return catalogs_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.datasets import FluxPointsDataset\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from gammapy.modeling.models import SkyModel, Models\n",
    "from gammapy.datasets import Datasets\n",
    "\n",
    "def get_datasets_flux_points_gammapy(region_of_interest):\n",
    "    '''\n",
    "    Select a catalog subset (only sources within a region of interest)\n",
    "    '''\n",
    "    \n",
    "    path_datasets = utl.get_path_datasets(region_of_interest)\n",
    "    try:\n",
    "        catalogs_roi = utl.unpickling_catalog_roi(region_of_interest)\n",
    "    except:\n",
    "        catalogs_roi = create_catalogs_region_of_interest(region_of_interest)\n",
    "        \n",
    "    datasets_counterparts = Datasets() # global datasets object\n",
    "    models_counterparts = Models()  # global models object\n",
    "    counterparts = [] # global sources object\n",
    "    \n",
    "    n_counterparts = 0 # number of counterparts\n",
    "    n_flux_points = 0 # number of flux points tables\n",
    "    \n",
    "    e_ref_min = region_of_interest[\"e_ref_min\"] \n",
    "    e_ref_max = region_of_interest[\"e_ref_max\"]\n",
    "    \n",
    "    #############################\n",
    "    if region_of_interest[\"name\"] == 'LHAASO J1839-0545':\n",
    "        for cat_tag in [\"gamma-cat\", \"hgps\"]:\n",
    "            hess.get_dataset_HESSJ1837069(counterparts, datasets_counterparts, models_counterparts, cat_tag)\n",
    "    #############################\n",
    "        \n",
    "    for catalog in catalogs_roi:\n",
    "        cat_tag = catalog.tag\n",
    "        for counterpart in catalog:\n",
    "            n_counterparts+=1   \n",
    "            counterpart_name = counterpart.name            \n",
    "            try:\n",
    "                flux_points = counterpart.flux_points\n",
    "\n",
    "                counterpart_spectral_model = counterpart.spectral_model()\n",
    "                spectral_model_tag = counterpart_spectral_model.tag[0]\n",
    "                spectral_model_tag_short = counterpart_spectral_model.tag[1]\n",
    "                \n",
    "                if cat_tag == 'gamma-cat' or cat_tag == 'hgps':\n",
    "                    ds_name = f'{counterpart_name}: {cat_tag}'\n",
    "                else: ds_name = counterpart_name\n",
    "                    \n",
    "                file_name = utl.name_to_txt(ds_name)\n",
    "                \n",
    "                counterpart_model = SkyModel(\n",
    "                    name = f\"{file_name}_{counterpart_spectral_model.tag[1]}\",\n",
    "                    spectral_model = counterpart_spectral_model,\n",
    "                    datasets_names=ds_name\n",
    "                )\n",
    "        \n",
    "                ds = FluxPointsDataset(\n",
    "                    models = counterpart_model,\n",
    "                    data = flux_points, \n",
    "                    name =  ds_name   \n",
    "                )\n",
    "                \n",
    "                if any([e_ref_min !=  None, e_ref_max !=  None]):\n",
    "                    ds = cut_flux_points_energy_range(ds, e_ref_min, e_ref_max)\n",
    "                \n",
    "                n_flux_points+=1\n",
    "                models_counterparts.append(counterpart_model)  # Add the counterpart_model to models()\n",
    "                \n",
    "                counterparts.append(counterpart)\n",
    "                datasets_counterparts.append(ds)\n",
    "                \n",
    "            except Exception as error:\n",
    "                # By this way we can know about the type of error occurring\n",
    "                print(f'The error is: ({counterpart_name}) {error}') \n",
    "            \n",
    "    datasets_counterparts.models = models_counterparts\n",
    "    # To save datasets and models\n",
    "    utl.write_datasets_models(datasets_counterparts,region_of_interest, \"counterparts_gammapy\")\n",
    "            \n",
    "    print(f\"Total number of counterparts: {n_counterparts}\")\n",
    "    print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "    return counterparts, datasets_counterparts, models_counterparts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
