{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4995abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "path_my_modules = 'my_modules'\n",
    "module_path = os.path.abspath(f'{path_my_modules}/config')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import cfg\n",
    "importlib.reload(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d23028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(f'{path_my_modules}/{cfg.dir_hawc_analysis}')\n",
    "if module_path not in sys.path:\n",
    "    print(sys.path.append(module_path))\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import hawc_analysis as hawc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(f'{path_my_modules}/{cfg.dir_cta_simulation}')\n",
    "if module_path not in sys.path:\n",
    "    print(sys.path.append(module_path))\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import cta_simulation as cta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22456a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.modeling import Fit\n",
    "from gammapy.datasets import Datasets\n",
    "from gammapy.modeling.models import Models\n",
    "\n",
    "def fit_Datasets(datasets, sky_model):\n",
    "    model_name = sky_model.name\n",
    "    datasets = Datasets(datasets)\n",
    "    sky_model = sky_model.copy(name = model_name)\n",
    "        \n",
    "    datasets.models = sky_model\n",
    "    # print(datasets)\n",
    "    fitter = Fit()\n",
    "    result_fit = fitter.run(datasets=datasets)\n",
    "    print(result_fit.parameters.to_table())\n",
    "    print(result_fit.total_stat)\n",
    "    \n",
    "#     models = Models(sky_model.copy(name= model_name)) \n",
    "#     file_path = utl.get_path_models(region_of_interest)\n",
    "#     # To save only the models\n",
    "#     models.write(f\"{file_path}/{model_name}.yaml\", model_name)\n",
    "    region_of_interest = create_region_of_interest()\n",
    "\n",
    "    write_datasets_models(datasets, region_of_interest, model_name)\n",
    "    return sky_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b812048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // In your script file\n",
    "def getVarFromFile(filename):\n",
    "    import imp\n",
    "    f = open(filename)\n",
    "    global data\n",
    "    data = imp.load_source('data', filename, f)\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_datasets_models(datasets,region_of_interest, directory_name, path_datasets = None):\n",
    "    \n",
    "    if path_datasets == None:\n",
    "        path_datasets = get_path_datasets(region_of_interest)        \n",
    "    \n",
    "    path_datasets, path_file = mkdir_sub_directory(str(path_datasets), directory_name)\n",
    "    datasets.write(filename=f\"{path_file}/datasets{cfg.format_yaml}\", filename_models=f\"{path_file}/models{cfg.format_yaml}\", overwrite=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datasets_models(region_of_interest, directory_name, path_datasets = None):\n",
    "    if path_datasets == None:\n",
    "        path_datasets = get_path_datasets(region_of_interest)  \n",
    "    path_datasets, path_file = mkdir_sub_directory(str(path_datasets), directory_name)\n",
    "    return Datasets.read(filename=f\"{path_file}/datasets{cfg.format_yaml}\", filename_models=f\"{path_file}/models{cfg.format_yaml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b638ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_name(pulsar_info, irf_name, skymodel_name): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return f\"{name_to_txt(pulsar_info['name'])}_irf_{irf_name}_{skymodel_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.catalog import CATALOG_REGISTRY \n",
    "\n",
    "def load_catalogs_from_gammapy():\n",
    "    \"\"\"\n",
    "    Load all available source catalogs in gammapy.catalog package into a list\n",
    "    \n",
    "    >>> load_catalogs_from_gammapy()\n",
    "    \n",
    "    Source catalogs in Gammapy: 8\n",
    "\n",
    "    (catalog index: 0) SourceCatalogGammaCat:\n",
    "        name: gamma-cat\n",
    "        description: An open catalog of gamma-ray sources\n",
    "        sources: 162\n",
    "\n",
    "    (catalog index: 1) SourceCatalogHGPS:\n",
    "        name: hgps\n",
    "        description: H.E.S.S. Galactic plane survey (HGPS) source catalog\n",
    "        sources: 78\n",
    "\n",
    "    (catalog index: 2) SourceCatalog2HWC:\n",
    "        name: 2hwc\n",
    "        description: 2HWC catalog from the HAWC observatory\n",
    "        sources: 40\n",
    "\n",
    "    (catalog index: 3) SourceCatalog3FGL:\n",
    "        name: 3fgl\n",
    "        description: LAT 4-year point source catalog\n",
    "        sources: 3034\n",
    "\n",
    "    (catalog index: 4) SourceCatalog4FGL:\n",
    "        name: 4fgl\n",
    "        description: LAT 8-year point source catalog\n",
    "        sources: 6659\n",
    "\n",
    "    (catalog index: 5) SourceCatalog2FHL:\n",
    "        name: 2fhl\n",
    "        description: LAT second high-energy source catalog\n",
    "        sources: 360\n",
    "\n",
    "    (catalog index: 6) SourceCatalog3FHL:\n",
    "        name: 3fhl\n",
    "        description: LAT third high-energy source catalog\n",
    "        sources: 1556\n",
    "\n",
    "    (catalog index: 7) SourceCatalog3HWC:\n",
    "        name: 3hwc\n",
    "        description: 3HWC catalog from the HAWC observatory\n",
    "        sources: 65\n",
    "    \"\"\"\n",
    "    source_catalogs = []\n",
    "    print (f\"Source catalogs in Gammapy: {len(CATALOG_REGISTRY)}\\n\")\n",
    "    for index, catalog in enumerate(CATALOG_REGISTRY):\n",
    "        #  FITS files are loaded\n",
    "        catalog_cls = CATALOG_REGISTRY.get_cls(catalog.tag)()\n",
    "        source_catalogs.append(catalog_cls)\n",
    "        print(f\"(catalog index: {index}) {source_catalogs[index]}\")\n",
    "\n",
    "    return source_catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "def set_source_info():\n",
    "    \"\"\"\n",
    "    Sets the source info into a dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_name : str\n",
    "        source name based on J2000 coordinates\n",
    "        \n",
    "    source_RA : float  \n",
    "        right ascension (in degrees) of the source position\n",
    "        \n",
    "    source_dec : float\n",
    "        declination (in degrees) of the source position\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    source_info : dict \n",
    "        dictionary with the source info (name and position)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> source_name = \"LHAASO J1825-1326\"  \n",
    "    >>> source_RA = 276.45* u.Unit(\"deg\")  \n",
    "    >>> source_dec = -13.45* u.Unit(\"deg\") \n",
    "    >>> set_source_info(source_name, source_RA, source_dec)\n",
    "    {'name': 'LHAASO J1825-1326',\n",
    "    'position': <SkyCoord (ICRS): (ra, dec) in deg\n",
    "    (276.45, -13.45)>}\n",
    "    \"\"\"\n",
    "    data = getVarFromFile(\"set_analysis.dat\")\n",
    "    source_name = data.source_name\n",
    "    pos_ra = data.pos_ra*u.Unit(cfg.unit_deg)\n",
    "    pos_dec = data.pos_dec*u.Unit(cfg.unit_deg)\n",
    "\n",
    "#     if any([source_RA.unit !=  cfg.unit_deg, source_dec.unit !=  cfg.unit_deg]):\n",
    "#         raise Exception(\"Sorry, there is a error: celestial coordinates (RA, dec.) units is not in degrees\") \n",
    "    \n",
    "    return  {\n",
    "        'name': source_name,\n",
    "        'position': SkyCoord(pos_ra, pos_dec) \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "\n",
    "def create_region_of_interest():\n",
    "    \"\"\"\n",
    "    Creates the region of interest\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_info : dict \n",
    "        dictionary with the source info (name and position)\n",
    "        \n",
    "    radius_roi : float\n",
    "        the maximum angle (in degrees) of separation between the source and its counterpart\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    region_of_interest : dict \n",
    "        dictionary with the region of interest info (source name, source position, angle of separation and roi name)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> source_name = \"LHAASO J1825-1326\"  \n",
    "    >>> source_RA = 276.45  \n",
    "    >>> source_dec = -13.45 \n",
    "    >>> source_info = set_source_info(source_name, source_RA, source_dec)\n",
    "    >>> radius_roi = 1\n",
    "    >>> create_region_of_interest(source_info, radius_roi)\n",
    "    \n",
    "    {'name': 'LHAASO J1825-1326',\n",
    "     'position': <SkyCoord (ICRS): (ra, dec) in deg\n",
    "     (276.45, -13.45)>,\n",
    "     'radius_roi': <Quantity 1. deg>}\n",
    "     \n",
    "    \"\"\"\n",
    "    source_info = set_source_info()\n",
    "\n",
    "    data = getVarFromFile(\"set_analysis.dat\")\n",
    "    radius_roi = data.radius_roi*u.Unit(cfg.unit_deg)\n",
    "    e_ref_min = data.e_ref_min\n",
    "    e_ref_max = data.e_ref_max\n",
    "    \n",
    "    if radius_roi.unit !=  cfg.unit_deg:\n",
    "        raise Exception(\"Sorry, there is a error: radius_roi unit is not in degrees\") \n",
    "        \n",
    "    if e_ref_min is not None and e_ref_max is not None:\n",
    "        if e_ref_min.unit != e_ref_max.unit:\n",
    "            raise Exception(f\"Sorry, there is a error: units is not iquals ({e_ref_min.unit} != {e_ref_max.unit})\") \n",
    "            \n",
    "        if e_ref_max.value <= e_ref_min.value:\n",
    "            raise Exception(f\"There is a error: e_ref_max ({e_ref_max}) <= e_ref_min ({e_ref_min})\") \n",
    "            \n",
    "    region_of_interest = source_info.copy()\n",
    "    region_of_interest[\"radius_roi\"] = radius_roi\n",
    "    region_of_interest[\"e_ref_min\"] = e_ref_min\n",
    "    region_of_interest[\"e_ref_max\"] = e_ref_max\n",
    "    region_of_interest[\"roi_name\"] = create_roi_name(source_info['name'], radius_roi, e_ref_min, e_ref_max)\n",
    "    \n",
    "#     print(\"**************************************************\", end = \"\\n\\n\")\n",
    "#     print(f\"Region of interest:\\n\")\n",
    "#     print(f'Source name: {region_of_interest['name']}')\n",
    "#     print(f'Source position (ra, dec) in deg: {region_of_interest['position'].ra.deg, region_of_interest['position'].dec.deg}')\n",
    "#     print(f\"Radius in deg: {radius_roi.value}\")\n",
    "#     print(f\"Energy ref min in deg: {radius_roi.value}\")\n",
    "    \n",
    "#     print(f\"Radius in deg: {radius_roi.value}\", end = \"\\n\\n**************************************************\\n\")\n",
    "    \n",
    "    return region_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8552d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cacd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roi_name(source_name, radius_roi, e_ref_min = None, e_ref_max = None): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    source_name = f\"{name_to_txt(source_name)}\"\n",
    "    radius_name = f\"_roi_{name_to_txt(str(radius_roi.value))}{name_to_txt(str(radius_roi.unit))}\"\n",
    "\n",
    "    if e_ref_min is not None:\n",
    "        e_ref_min_name = f\"_e_ref_min_{name_to_txt(str(e_ref_min.value))}{e_ref_min.unit}\"\n",
    "    else:\n",
    "        e_ref_min_name = \"\"\n",
    "        \n",
    "    if e_ref_max is not None:\n",
    "        e_ref_max_name = f\"_e_ref_max_{name_to_txt(str(e_ref_max.value))}{e_ref_max.unit}\"\n",
    "    else:\n",
    "        e_ref_max_name = \"\"   \n",
    "    \n",
    "    return(f\"{source_name}{radius_name}{e_ref_min_name}{e_ref_max_name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83fcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_counterparts(region_of_interest):\n",
    "    import pandas as pd \n",
    "    df_columns=[]\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    catalogs_roi = unpickling_catalog_roi(region_of_interest)\n",
    "\n",
    "    for catalog in catalogs_roi:\n",
    "        cat_tag = catalog.tag\n",
    "\n",
    "        for counterpart in catalog:\n",
    "            try: \n",
    "                flux_points = counterpart.flux_points\n",
    "                flux_points_table = \"Yes\"\n",
    "            except:\n",
    "                flux_points_table = \"No\"\n",
    "                                     \n",
    "            sep = counterpart.position.separation(region_of_interest['position']).deg\n",
    "            pos_dec = counterpart.position.dec.deg\n",
    "            pos_ra = counterpart.position.ra.deg\n",
    "            if cat_tag != 'gamma-cat' and cat_tag != 'hgps':\n",
    "                name = counterpart.name\n",
    "            else:\n",
    "                name = f\"{counterpart.name} ({cat_tag})\"\n",
    "            df_column = [name,\"{:.2f}\".format(pos_ra) , \"{:.2f}\".format(pos_dec), \"{:.2f}\".format(sep), flux_points_table]\n",
    "            df_columns.append(df_column)\n",
    "\n",
    "    df = pd.DataFrame(df_columns, columns = ['Source name', 'RA(deg)', 'dec.(deg)', 'Sep.(deg)', 'Flux points']) \n",
    "    df = df.reset_index(drop = True)\n",
    "    df.index.name = 'Source index'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4146ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_sources_gammapy(sources_gammapy, datasets_gammapy):\n",
    "    dict_sources_gammapy = {}\n",
    "    for index, (source, dataset) in enumerate(zip(sources_gammapy, datasets_gammapy)):\n",
    "        dict_sources_gammapy[dataset.name] = {'position': source.position}\n",
    "    return dict_sources_gammapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.modeling.models import Models\n",
    "from gammapy.datasets import Datasets\n",
    "\n",
    "def joint_datasets(datasets_gammapy, models_gammapy, datasets_outside_gammapy, models_outside_gammapy):\n",
    "    datasets_roi = Datasets()\n",
    "    models_roi = Models()\n",
    "    for index, (dataset, model) in enumerate(zip(datasets_gammapy, models_gammapy)):\n",
    "        datasets_roi.append(dataset)\n",
    "        models_roi.append(model)\n",
    "        print(index, dataset.name)\n",
    "    for index_, (dataset, model) in enumerate(zip(datasets_outside_gammapy, models_outside_gammapy)):\n",
    "        datasets_roi.append(dataset)\n",
    "        models_roi.append(model)\n",
    "        print(index_+index+1, dataset.name)\n",
    "    datasets_roi.models = models_roi\n",
    "    return datasets_roi, models_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "def get_dict_data_frame_roi(sources_gammapy, datasets_gammapy, datasets_roi, region_of_interest):\n",
    "    \n",
    "    df_columns=[]\n",
    "    df = pd.DataFrame()\n",
    "    dict_sources_gammapy = get_dict_sources_gammapy(sources_gammapy, datasets_gammapy)\n",
    "    dict_HAWC = hawc.get_dict()\n",
    "    dict_pulsars = cta.get_dict_pulsars()\n",
    "\n",
    "    dict_roi = {}\n",
    "    columns = ['Source name', 'RA(deg)', 'dec.(deg)', 'Sep.(deg)']\n",
    "    for index, source_name in enumerate(datasets_roi.names):\n",
    "        roi_pos = region_of_interest[\"position\"]\n",
    "        radius_roi = region_of_interest[\"radius_roi\"]\n",
    "\n",
    "        if source_name in list(dict_sources_gammapy.keys()):\n",
    "            source_pos = dict_sources_gammapy[source_name][\"position\"]\n",
    "            pos_dec = source_pos.dec.deg\n",
    "            pos_ra = source_pos.ra.deg\n",
    "            sep = source_pos.separation(roi_pos).deg\n",
    "            df_column = [source_name,\"{:.2f}\".format(pos_ra) , \"{:.2f}\".format(pos_dec), \"{:.2f}\".format(sep)]\n",
    "            df_columns.append(df_column)\n",
    "            dict_roi[source_name] = {\n",
    "                'position': source_pos,\n",
    "                'separation':sep }\n",
    "\n",
    "        if source_name in list(dict_HAWC.keys()):\n",
    "            source_pos = dict_HAWC[source_name][\"position\"]\n",
    "            pos_dec = source_pos.dec.deg\n",
    "            pos_ra = source_pos.ra.deg\n",
    "            sep = source_pos.separation(roi_pos).deg\n",
    "            df_column = [source_name,\"{:.2f}\".format(pos_ra) , \"{:.2f}\".format(pos_dec), \"{:.2f}\".format(sep)]\n",
    "            df_columns.append(df_column)\n",
    "            dict_roi[source_name] = {\n",
    "                'position': source_pos,\n",
    "                'separation':sep }\n",
    "    #     else: \n",
    "    #         source_pos = dict_LHAASO[name][\"position\"]\n",
    "    #         sep = source_pos.separation(roi_pos).deg\n",
    "    #         print(name, sep)\n",
    "\n",
    "    for index, source_name in enumerate(list(dict_pulsars.keys())):\n",
    "            source_pos = dict_pulsars[source_name][\"position\"]\n",
    "            pos_dec = source_pos.dec.deg\n",
    "            pos_ra = source_pos.ra.deg\n",
    "            sep = source_pos.separation(roi_pos)\n",
    "            if sep <= radius_roi:\n",
    "                sep = sep.deg\n",
    "                df_column = [source_name,\"{:.2f}\".format(pos_ra) , \"{:.2f}\".format(pos_dec), \"{:.2f}\".format(sep)]\n",
    "                df_columns.append(df_column)\n",
    "                dict_roi[source_name] = {\n",
    "                    'position': source_pos,\n",
    "                    'separation':sep }\n",
    "\n",
    "    df = pd.DataFrame(df_columns, columns = columns) \n",
    "    df = df.reset_index(drop = True)\n",
    "    return dict_roi, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.datasets import FluxPointsDataset\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from gammapy.modeling.models import SkyModel, Models\n",
    "from gammapy.datasets import Datasets\n",
    "\n",
    "def get_flux_points_datasets(region_of_interest):\n",
    "    '''\n",
    "    Select a catalog subset (only sources within a region of interest)\n",
    "    '''\n",
    "    \n",
    "    # Creates the directories to save the flux points tables \n",
    "#     directory_file = f'{cfg.dir_flux_points_tables}/{region_of_interest[\"roi_name\"]}'\n",
    "#     path_analysis, path_file = mkdir_sub_directory(cfg.dir_analysis, directory_file)\n",
    "    path_file = get_path_tables(region_of_interest)\n",
    "    catalogs_roi = unpickling_catalog_roi(region_of_interest)\n",
    "\n",
    "    datasets_counterparts = Datasets() # global datasets object\n",
    "    models_counterparts = Models()  # global models object\n",
    "    counterparts = [] # global sources object\n",
    "    \n",
    "    n_counterparts = 0 # number of counterparts\n",
    "    n_flux_points = 0 # number of flux points tables\n",
    "\n",
    "    for catalog in catalogs_roi:\n",
    "        cat_tag = catalog.tag\n",
    "        for counterpart in catalog:\n",
    "            n_counterparts+=1   \n",
    "            counterpart_name = counterpart.name            \n",
    "            try: \n",
    "                counterpart_flux_points = counterpart.flux_points\n",
    "                n_flux_points+=1\n",
    "                counterpart_spectral_model = counterpart.spectral_model()\n",
    "                spectral_model_tag = counterpart_spectral_model.tag[0]\n",
    "                spectral_model_tag_short = counterpart_spectral_model.tag[1]\n",
    "        \n",
    "                if cat_tag != 'gamma-cat' and cat_tag != 'hgps':\n",
    "                    ds_name = f\"{counterpart_name}\"\n",
    "                else:\n",
    "                    ds_name = f\"{counterpart_name}: {cat_tag}\"\n",
    "                     \n",
    "                file_name = name_to_txt(ds_name)\n",
    "    \n",
    "                counterpart_model = SkyModel(\n",
    "                    name = f\"{file_name}_{counterpart_spectral_model.tag[1]}\",\n",
    "                    spectral_model = counterpart_spectral_model,\n",
    "                    datasets_names=ds_name\n",
    "                )\n",
    "                models_counterparts.append(counterpart_model)  # Add the counterpart_model to models()\n",
    "        \n",
    "                ds = FluxPointsDataset(\n",
    "                    models = counterpart_model,\n",
    "                    data = counterpart_flux_points, \n",
    "                    name =  ds_name   \n",
    "                )\n",
    "                counterparts.append(counterpart)\n",
    "                datasets_counterparts.append(ds)\n",
    "                \n",
    "                table = ds.data.to_table(sed_type = cfg.sed_type_e2dnde, formatted = True)\n",
    "\n",
    "                # Writes the flux points table in the csv/fits format\n",
    "                write_tables_csv(table, path_file, file_name)\n",
    "                write_tables_fits(table, path_file, file_name)\n",
    "                \n",
    "            except Exception as error:\n",
    "                # By this way we can know about the type of error occurring\n",
    "                print(f\"The error is: ({counterpart_name}) {error}\") \n",
    "                            \n",
    "    print(f\"Total number of counterparts: {n_counterparts}\")\n",
    "    print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "    return counterparts, datasets_counterparts, models_counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313231ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gammapy.datasets import FluxPointsDataset\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "import pickle\n",
    "\n",
    "def get_catalogs_region_of_interest(source_catalogs, region_of_interest):\n",
    "    \"\"\"\n",
    "    Gets catalogs subset (only sources within the region of interest)\n",
    "    \"\"\"\n",
    "    \n",
    "    source_position = region_of_interest['position'] \n",
    "    radius_roi = region_of_interest[\"radius_roi\"] \n",
    "    \n",
    "    print(\"**************************************************\", end = \"\\n\\n\")\n",
    "    print(f\"Region of interest:\\n\")\n",
    "    print(f\"Source name: {region_of_interest['name']}\")\n",
    "    print(f\"Source position (ra, dec) in deg: {region_of_interest['position'].ra.deg, region_of_interest['position'].dec.deg}\")\n",
    "    print(f\"Radius in deg: {radius_roi.value}\", end = \"\\n\\n**************************************************\\n\")\n",
    "    \n",
    "    catalogs_roi = []\n",
    "    catalogs_no_counterparts = []\n",
    "    numbers_catalogs_roi = 0\n",
    "    \n",
    "    for catalog in source_catalogs:        \n",
    "        # Selects only sources within the region of interest. \n",
    "        mask_roi = source_position.separation(catalog.positions) < radius_roi \n",
    "        \n",
    "        if len(catalog[mask_roi].table):\n",
    "            catalogs_roi.append(catalog[mask_roi])\n",
    "            numbers_catalogs_roi += 1\n",
    "        else:\n",
    "            catalogs_no_counterparts.append(f\"{catalog.tag}: {catalog.description}\")\n",
    "    \n",
    "            \n",
    "    if numbers_catalogs_roi:\n",
    "        pickling_catalog_roi(catalogs_roi, region_of_interest)\n",
    "        print(f\"\\n{numbers_catalogs_roi} catalogs with sources within the region of interest:\", end = \"\\n\\n\")\n",
    "        for catalog in catalogs_roi:\n",
    "            print(f\"{catalog.tag}: {catalog.description}\")\n",
    "            display(catalog.table)\n",
    "    else:\n",
    "        print(\"No catalogs with sources in the region of interest!\", end = \"\\n\\n\")\n",
    "\n",
    "    if numbers_catalogs_roi and len(catalogs_no_counterparts):\n",
    "        print(\"Catalogs without sources within the region of interest:\", end = \"\\n\\n\")\n",
    "        for index, catalog_no_counterpart in enumerate(catalogs_no_counterparts):                            \n",
    "            print(catalog_no_counterpart)\n",
    "\n",
    "    return catalogs_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from astropy import units as u\n",
    "from astropy.table import Table\n",
    "from gammapy.estimators import FluxPoints\n",
    "from gammapy.utils.scripts import make_path\n",
    "\n",
    "\n",
    "from gammapy.datasets import FluxPointsDataset\n",
    "\n",
    "def cut_flux_points_in_energy(datasets_counterparts, region_of_interest):\n",
    "    e_ref_min = region_of_interest[\"e_ref_min\"]\n",
    "    \n",
    "    e_ref_min_txt = name_to_txt(str(e_ref_min))\n",
    "    source_txt  = name_to_txt(region_of_interest['name'])\n",
    "    radius_roi_txt = name_to_txt(str(region_of_interest[\"radius_roi\"]))+'degree'\n",
    "\n",
    "    # Creates the directories to save the flux points tables \n",
    "    path_tables = get_path_tables(region_of_interest)\n",
    "    \n",
    "    datasets_cut_fp = Datasets()\n",
    "    for index, dataset_fp in enumerate(datasets_counterparts):\n",
    "        ds_name = dataset_fp.name\n",
    "        flux_points= dataset_fp.data\n",
    "        try:\n",
    "            mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "            for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "                if e_ref >= e_ref_min:\n",
    "                    mask_energy[m] = True\n",
    "\n",
    "            flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "            flux_points_energy = FluxPoints.from_table(flux_points_mask)\n",
    "\n",
    "            ds = FluxPointsDataset(\n",
    "                models = dataset_fp.models[0],\n",
    "                data=flux_points_energy, \n",
    "                name = ds_name\n",
    "            )\n",
    "\n",
    "            datasets_cut_fp.append(ds)\n",
    "            table = ds.data.to_table(\n",
    "                sed_type = cfg.sed_type_e2dnde,\n",
    "                formatted = True\n",
    "            )    \n",
    "            file_name = name_to_txt(ds_name)            \n",
    "            write_tables_csv(table, path_tables, file_name)\n",
    "\n",
    "        except Exception as error:\n",
    "            print(f\"The error ({dataset_fp.name}) is: {error}\") \n",
    "    return datasets_cut_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf658db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickling_catalog_roi(catalogs_roi, region_of_interest):        \n",
    "    \n",
    "    # Creates the directory to save the list of catalogs roi  \n",
    "#     path_analysis, path_file = mkdir_sub_directory(cfg.dir_analysis, cfg.dir_catalogs_roi)\n",
    "    path_file = get_path_catalogs_roi()\n",
    "    \n",
    "    file_name = f\"catalog_{create_roi_name(region_of_interest['name'], region_of_interest['radius_roi'], region_of_interest['e_ref_min'])}\"\n",
    "    \n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_dat}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)       \n",
    "\n",
    "    with open(path_os, \"wb\") as fp:  \n",
    "        pickle.dump(catalogs_roi, fp)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "def unpickling_catalog_roi(region_of_interest):        \n",
    "    # Creates the directory to save the catalogs roi list  \n",
    "#     path_analysis, path_file = mkdir_sub_directory(cfg.dir_analysis, cfg.dir_catalogs_roi)\n",
    "    path_file = get_path_catalogs_roi()\n",
    "    file_name = f\"catalog_{create_roi_name(region_of_interest['name'], region_of_interest['radius_roi'], region_of_interest['e_ref_min'])}\"\n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_dat}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)       \n",
    "\n",
    "    with open(path_os, \"rb\") as fp:  \n",
    "        catalogs_roi = pickle.load(fp)\n",
    "    return catalogs_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db794ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/born-again/Documents/GitHub/CTA_projects/my_modules/counterparts_analysis'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fca12bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/born-again/Documents/GitHub/CTA_projects'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_analysis():\n",
    "    return mkdir_sub_directory(cfg.dir_analysis)\n",
    "\n",
    "def get_path_catalogs_roi():\n",
    "    path_analysis, path_catalogs_roi = mkdir_sub_directory(str(get_path_analysis()), cfg.dir_catalogs_roi)\n",
    "    return path_catalogs_roi\n",
    "\n",
    "def get_path_datasets(region_of_interest= None):\n",
    "    if region_of_interest:\n",
    "        path_analysis, path_datasets = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_datasets}/{region_of_interest['roi_name']}\" )\n",
    "    else: \n",
    "        path_analysis, path_datasets = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_datasets}\" )\n",
    "\n",
    "    return path_datasets\n",
    "\n",
    "def get_path_models(region_of_interest = None):\n",
    "    if region_of_interest:\n",
    "        path_analysis, path_models = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_models}/{region_of_interest['roi_name']}\")\n",
    "    else:\n",
    "        path_analysis, path_models = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_models}\")        \n",
    "    return path_models\n",
    "\n",
    "def get_path_tables(region_of_interest = None):\n",
    "    if region_of_interest:\n",
    "        path_analysis, path_tables = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_tables}/{region_of_interest['roi_name']}\")\n",
    "    else:\n",
    "        path_analysis, path_tables = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_tables}\")\n",
    "    return path_tables\n",
    "\n",
    "def get_path_figures():\n",
    "    path_analysis, path_figures = mkdir_sub_directory(str(get_path_analysis()), cfg.dir_figures)\n",
    "    return path_figures\n",
    "\n",
    "def get_path_SED_from_catalogs(region_of_interest):\n",
    "    path_figures, path_SED_from_catalogs = mkdir_sub_directory(str(get_path_figures()), f\"{cfg.dir_SED_from_catalogs}/{region_of_interest['roi_name']}\")\n",
    "    return path_SED_from_catalogs\n",
    "\n",
    "def get_path_SED(region_of_interest):\n",
    "    path_figures, path_SED = mkdir_sub_directory(str(get_path_figures()), f\"{cfg.dir_SED}/{region_of_interest['roi_name']}\")\n",
    "    return path_SED\n",
    "\n",
    "def get_path_flux_points(region_of_interest):\n",
    "    path_figures, path_flux_points = mkdir_sub_directory(str(get_path_figures()), f\"{cfg.dir_flux_points}/{region_of_interest['roi_name']}\")\n",
    "    return path_flux_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_sub_directory(parent_directory = None, child_directory = None):\n",
    "    '''Creates a directory: parent_directory/child_directory and returs the path \n",
    "    >>>mkdir_sub_directory(parent_directory, directory)\n",
    "    path_parent, path_child\n",
    "    '''\n",
    "    if child_directory is None:\n",
    "\n",
    "        path_parent = Path(f\"{parent_directory}\")\n",
    "        path_parent.mkdir(exist_ok=True)\n",
    "#         print(\"Directory '% s' created\" % path_parent)\n",
    "        \n",
    "        return path_parent\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        path_parent = Path(f\"{parent_directory}\")\n",
    "        path_parent.mkdir(exist_ok=True)\n",
    "\n",
    "        path_child = Path(f\"{path_parent}/{child_directory}\")\n",
    "        path_child.mkdir(parents=True, exist_ok=True)\n",
    "#         print(\"Directory '% s' created\" % path_child)\n",
    "\n",
    "        return (path_parent, path_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_txt(name):\n",
    "    '''Given a `string`, `find` and `replace` the space by \"_\" and . by \"dot\"\n",
    "    >>> name_to_txt(n ame.)\n",
    "    namedot\n",
    "    '''\n",
    "    return name.replace(\" \", \"_\").replace(\".\", \"dot\").replace(\":\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96ef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c50bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_txt(num):\n",
    "    '''Given a `number`, return a string\n",
    "    >>> number_to_txt(num = 1.002222):\n",
    "    1\n",
    "    '''\n",
    "    return (\"%.2f\" % num).rstrip('0').rstrip('.').replace(\".\", \"dot\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de1925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1d7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.estimators import FluxPoints\n",
    "\n",
    "def ds_fp_from_table_fp(table, sky_model, source_name, sed_type = \"e2dnde\"):\n",
    "    '''Returns the flux points dataset from the flux points table \n",
    "    \n",
    "    >>> ds_fp_from_table_fp(table, sky_model, sed_type)\n",
    "    ds_fp\n",
    "    '''\n",
    "    flux_points = FluxPoints.from_table(table = table, reference_model = sky_model, sed_type=sed_type)\n",
    "    \n",
    "    ds_name = f\"{source_name}\"  \n",
    "    ds_fp = FluxPointsDataset(\n",
    "        models = sky_model,\n",
    "        data   = flux_points, \n",
    "        name   = ds_name\n",
    "    )\n",
    "    return ds_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def write_tables_csv(table, path_file, file_name):\n",
    "# Writes the flux points table in the csv format\n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_csv}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)\n",
    "\n",
    "    table.write(\n",
    "        f\"{path_os}\",\n",
    "        format = 'ascii.ecsv', \n",
    "        overwrite = True\n",
    "    )   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373eaa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def write_tables_fits(table, path_file, file_name):\n",
    "    # Writes the flux points table in the fits format\n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_fits}\"\n",
    "        )\n",
    "    )      \n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)\n",
    "\n",
    "    table.write(\n",
    "        f\"{path_os}\",\n",
    "        format = 'fits', \n",
    "        overwrite = True\n",
    "    )   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5a331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73125503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module_path = os.path.abspath(f'{path_my_modules}/lhaaso')\n",
    "# if module_path not in sys.path:\n",
    "#     print(sys.path.append(module_path))\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "# import lhaaso\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
