{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "path_modules = 'my_modules'\n",
    "\n",
    "module_path = os.path.abspath(f'{path_modules}/config')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import cfg\n",
    "importlib.reload(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e685d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.catalog import CATALOG_REGISTRY \n",
    "\n",
    "def load_catalogs_from_gammapy():\n",
    "    \"\"\"\n",
    "    Load all available source catalogs in Gammapy into a list\n",
    "    \n",
    "    >>> load_catalogs_from_gammapy()\n",
    "    \n",
    "    Source Catalogs: 8\n",
    "\n",
    "    (catalog index: 0) SourceCatalogGammaCat:\n",
    "        name: gamma-cat\n",
    "        description: An open catalog of gamma-ray sources\n",
    "        sources: 162\n",
    "\n",
    "    (catalog index: 1) SourceCatalogHGPS:\n",
    "        name: hgps\n",
    "        description: H.E.S.S. Galactic plane survey (HGPS) source catalog\n",
    "        sources: 78\n",
    "\n",
    "    (catalog index: 2) SourceCatalog2HWC:\n",
    "        name: 2hwc\n",
    "        description: 2HWC catalog from the HAWC observatory\n",
    "        sources: 40\n",
    "\n",
    "    (catalog index: 3) SourceCatalog3FGL:\n",
    "        name: 3fgl\n",
    "        description: LAT 4-year point source catalog\n",
    "        sources: 3034\n",
    "\n",
    "    (catalog index: 4) SourceCatalog4FGL:\n",
    "        name: 4fgl\n",
    "        description: LAT 8-year point source catalog\n",
    "        sources: 6659\n",
    "\n",
    "    (catalog index: 5) SourceCatalog2FHL:\n",
    "        name: 2fhl\n",
    "        description: LAT second high-energy source catalog\n",
    "        sources: 360\n",
    "\n",
    "    (catalog index: 6) SourceCatalog3FHL:\n",
    "        name: 3fhl\n",
    "        description: LAT third high-energy source catalog\n",
    "        sources: 1556\n",
    "\n",
    "    (catalog index: 7) SourceCatalog3HWC:\n",
    "        name: 3hwc\n",
    "        description: 3HWC catalog from the HAWC observatory\n",
    "        sources: 65\n",
    "    \"\"\"\n",
    "    \n",
    "    print (f\"Source Catalogs: {len(CATALOG_REGISTRY)}\\n\")\n",
    "    source_catalogs = []\n",
    "    for index, catalog in enumerate(CATALOG_REGISTRY):\n",
    "        #  FITS files are loaded\n",
    "        catalog_cls = CATALOG_REGISTRY.get_cls(catalog.tag)()\n",
    "        source_catalogs.append(catalog_cls)\n",
    "        print(f\"(catalog index: {index}) {source_catalogs[index]}\")\n",
    "\n",
    "    return source_catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67842910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "def set_source_info(source_name, source_RA, source_dec):\n",
    "    \"\"\"\n",
    "    Sets the source info into a dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_name : str\n",
    "        source name based on J2000 coordinates\n",
    "        \n",
    "    source_RA : float  \n",
    "        right ascension (in degrees) of the source position\n",
    "        \n",
    "    source_dec : float\n",
    "        declination (in degrees) of the source position\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    source_info : dict \n",
    "        dictionary with the source info (name and position)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> source_name = \"LHAASO J1825-1326\"  \n",
    "    >>> source_RA = 276.45  \n",
    "    >>> source_dec = -13.45 \n",
    "    >>> set_source_info(source_name, source_RA, source_dec)\n",
    "    {'source_name': 'LHAASO J1825-1326',\n",
    "    'source_position': <SkyCoord (ICRS): (ra, dec) in deg\n",
    "    (276.45, -13.45)>}\n",
    "    \"\"\"\n",
    "    return  {\n",
    "        \"source_name\": source_name,\n",
    "        \"source_position\": SkyCoord(source_RA, source_dec, unit = cfg.unit_deg) \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "\n",
    "def create_region_of_interest(source_info, radius_roi, e_ref_min = None):\n",
    "    \"\"\"\n",
    "    Creates the region of interest\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_info : dict \n",
    "        dictionary with the source info (name and position)\n",
    "        \n",
    "    radius_roi : float\n",
    "        the maximum angle (in degrees) of separation between the source and its counterpart\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    region_of_interest : dict \n",
    "        dictionary with the region of interest info (source name, source position, angle of separation and roi name)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> source_name = \"LHAASO J1825-1326\"  \n",
    "    >>> source_RA = 276.45  \n",
    "    >>> source_dec = -13.45 \n",
    "    >>> source_info = set_source_info(source_name, source_RA, source_dec)\n",
    "    >>> radius_roi = 1\n",
    "    >>> create_region_of_interest(source_info, radius_roi)\n",
    "    \n",
    "    {'source_name': 'LHAASO J1825-1326',\n",
    "     'source_position': <SkyCoord (ICRS): (ra, dec) in deg\n",
    "     (276.45, -13.45)>,\n",
    "     'radius_roi': <Quantity 1. deg>}\n",
    "     \n",
    "    \"\"\"\n",
    "    region_of_interest = source_info.copy()\n",
    "    region_of_interest[\"radius_roi\"] = radius_roi\n",
    "    if e_ref_min is None:\n",
    "        region_of_interest[\"e_ref_min\"] = None\n",
    "        region_of_interest[\"roi_name\"] = create_roi_name(source_info['source_name'], radius_roi)\n",
    "        \n",
    "    else:\n",
    "        region_of_interest[\"e_ref_min\"] = e_ref_min\n",
    "        region_of_interest[\"roi_name\"] = create_roi_name(source_info['source_name'], radius_roi, e_ref_min)\n",
    "    return region_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cacd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roi_name(source_name, radius_roi, e_ref_min = None): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    radius_name = f\"{name_to_txt(str(radius_roi.value))}{name_to_txt(str(radius_roi.unit))}\"\n",
    "    if e_ref_min is None:\n",
    "        return f\"{name_to_txt(source_name)}_roi_{radius_name}\"\n",
    "    else:\n",
    "        e_ref_min_name = f\"{name_to_txt(str(e_ref_min.value))}{e_ref_min.unit}\"\n",
    "        return f\"{name_to_txt(source_name)}_roi_{radius_name}_e_ref_min_{e_ref_min_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83fcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame_counterparts(region_of_interest):\n",
    "    import pandas as pd \n",
    "    df_columns=[]\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    catalogs_roi = unpickling_catalog_roi(region_of_interest)\n",
    "\n",
    "    for catalog in catalogs_roi:\n",
    "        cat_tag = catalog.tag\n",
    "\n",
    "        for counterpart in catalog:\n",
    "            try: \n",
    "                flux_points = counterpart.flux_points\n",
    "                flux_points_table = \"Yes\"\n",
    "            except:\n",
    "                flux_points_table = \"No\"\n",
    "                            \n",
    "                \n",
    "            sep = counterpart.position.separation(region_of_interest[\"source_position\"]).deg\n",
    "            pos_dec = counterpart.position.dec.deg\n",
    "            pos_ra = counterpart.position.ra.deg\n",
    "            if cat_tag != 'gamma-cat' and cat_tag != 'hgps':\n",
    "                name = counterpart.name\n",
    "            else:\n",
    "                name = f\"{counterpart.name} ({cat_tag})\"\n",
    "            df_column = [name,\"{:.2f}\".format(pos_ra) , \"{:.2f}\".format(pos_dec), \"{:.2f}\".format(sep), flux_points_table]\n",
    "            df_columns.append(df_column)\n",
    "\n",
    "    df = pd.DataFrame(df_columns, columns = ['Source name', 'RA(deg)', 'dec.(deg)', 'Sep.(deg)', 'Flux points']) \n",
    "    df = df.reset_index(drop = True)\n",
    "    df.index.name = 'Source index'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.datasets import FluxPointsDataset\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from gammapy.modeling.models import SkyModel, Models\n",
    "from gammapy.datasets import Datasets\n",
    "\n",
    "def get_flux_points_datasets(region_of_interest):\n",
    "    '''\n",
    "    Select a catalog subset (only sources within a region of interest)\n",
    "    '''\n",
    "    \n",
    "    # Creates the directories to save the flux points tables \n",
    "#     directory_file = f'{cfg.dir_flux_points_tables}/{region_of_interest[\"roi_name\"]}'\n",
    "#     path_analysis, path_file = mkdir_sub_directory(cfg.dir_analysis, directory_file)\n",
    "    path_file = get_path_tables(region_of_interest)\n",
    "    catalogs_roi = unpickling_catalog_roi(region_of_interest)\n",
    "\n",
    "    datasets_counterparts = Datasets()\n",
    "    models_counterparts = Models()  # global models object\n",
    "    \n",
    "    counterparts = []\n",
    "    n_counterparts = 0 # number of counterparts\n",
    "    n_flux_points = 0 # number of flux points tables\n",
    "\n",
    "    for catalog in catalogs_roi:\n",
    "        cat_tag = catalog.tag\n",
    "        for counterpart in catalog:\n",
    "            n_counterparts+=1   \n",
    "            counterpart_name = counterpart.name            \n",
    "            try: \n",
    "                counterpart_flux_points = counterpart.flux_points\n",
    "                n_flux_points+=1\n",
    "                counterpart_spectral_model = counterpart.spectral_model()\n",
    "                spectral_model_tag = counterpart_spectral_model.tag[0]\n",
    "                spectral_model_tag_short = counterpart_spectral_model.tag[1]\n",
    "        \n",
    "                if cat_tag != 'gamma-cat' and cat_tag != 'hgps':\n",
    "                    ds_name = f\"{counterpart_name}\"\n",
    "                else:\n",
    "                    ds_name = f\"{counterpart_name}: {cat_tag}\"\n",
    "                     \n",
    "                file_name = f\"{name_to_txt(counterpart_name)}_{cat_tag}\"\n",
    "    \n",
    "                counterpart_model = SkyModel(\n",
    "                    name = ds_name,\n",
    "                    spectral_model = counterpart_spectral_model,\n",
    "                    datasets_names=ds_name\n",
    "                )\n",
    "                models_counterparts.append(counterpart_model)  # Add the counterpart_model to models()\n",
    "        \n",
    "                ds = FluxPointsDataset(\n",
    "                    models = counterpart_model,\n",
    "                    data = counterpart_flux_points, \n",
    "                    name =  ds_name   \n",
    "                )\n",
    "                counterparts.append(counterpart)\n",
    "                datasets_counterparts.append(ds)\n",
    "                \n",
    "                table = ds.data.to_table(sed_type = cfg.sed_type_e2dnde, formatted = True)\n",
    "\n",
    "                # Writes the flux points table in the csv/fits format\n",
    "                write_tables_csv(table, path_file, file_name)\n",
    "                write_tables_fits(table, path_file, file_name)\n",
    "                \n",
    "            except Exception as error:\n",
    "                # By this way we can know about the type of error occurring\n",
    "                print(f'The error ({counterpart_name}) is: {error}') \n",
    "                            \n",
    "    print(f\"Total number of counterparts: {n_counterparts}\")\n",
    "    print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "    return counterparts, datasets_counterparts, models_counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313231ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gammapy.datasets import FluxPointsDataset\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "\n",
    "import pickle\n",
    "\n",
    "def get_catalogs_region_of_interest(source_catalogs, region_of_interest):\n",
    "    \"\"\"\n",
    "    Gets catalogs subset (only sources within the region of interest)\n",
    "    \"\"\"\n",
    "    \n",
    "    source_position = region_of_interest[\"source_position\"] \n",
    "    radius_roi = region_of_interest[\"radius_roi\"] \n",
    "    \n",
    "    print(\"**************************************************\", end = \"\\n\\n\")\n",
    "    print(f\"Region of interest:\\n\")\n",
    "    print(f'Source name: {region_of_interest[\"source_name\"]}')\n",
    "    print(f'Source position (ra, dec) in deg: {region_of_interest[\"source_position\"].ra.deg, region_of_interest[\"source_position\"].dec.deg}')\n",
    "    print(f\"Radius in deg: {radius_roi.value}\", end = \"\\n\\n**************************************************\\n\")\n",
    "    \n",
    "    catalogs_roi = []\n",
    "    catalogs_no_counterparts = []\n",
    "    numbers_catalogs_roi = 0\n",
    "    \n",
    "    for catalog in source_catalogs:        \n",
    "        # Selects only sources within the region of interest. \n",
    "        mask_roi = source_position.separation(catalog.positions) < radius_roi \n",
    "        \n",
    "        if len(catalog[mask_roi].table):\n",
    "            catalogs_roi.append(catalog[mask_roi])\n",
    "            numbers_catalogs_roi += 1\n",
    "        else:\n",
    "            catalogs_no_counterparts.append(f\"{catalog.tag}: {catalog.description}\")\n",
    "\n",
    "    if numbers_catalogs_roi:\n",
    "        pickling_catalog_roi(catalogs_roi, region_of_interest)\n",
    "        print(f\"\\n{numbers_catalogs_roi} catalogs with sources within the region of interest:\", end = \"\\n\\n\")\n",
    "        for catalog in catalogs_roi:\n",
    "            print(f\"{catalog.tag}: {catalog.description}\")\n",
    "            display(catalog.table)\n",
    "    else:\n",
    "        print(\"No catalogs with sources in the region of interest!\", end = \"\\n\\n\")\n",
    "\n",
    "    if numbers_catalogs_roi and len(catalogs_no_counterparts):\n",
    "        print(\"Catalogs without sources within the region of interest:\", end = \"\\n\\n\")\n",
    "        for index, catalog_no_counterpart in enumerate(catalogs_no_counterparts):                            \n",
    "            print(catalog_no_counterpart)\n",
    "\n",
    "    return catalogs_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from astropy import units as u\n",
    "from astropy.table import Table\n",
    "from gammapy.estimators import FluxPoints\n",
    "from gammapy.utils.scripts import make_path\n",
    "\n",
    "\n",
    "from gammapy.datasets import FluxPointsDataset\n",
    "\n",
    "def cut_flux_points_in_energy(datasets_counterparts, region_of_interest):\n",
    "    e_ref_min = region_of_interest[\"e_ref_min\"]\n",
    "    \n",
    "    e_ref_min_txt = name_to_txt(str(e_ref_min))\n",
    "    source_txt  = name_to_txt(region_of_interest[\"source_name\"])\n",
    "    radius_roi_txt = name_to_txt(str(region_of_interest[\"radius_roi\"]))+'degree'\n",
    "\n",
    "    # Creates the directories to save the flux points tables \n",
    "    path_tables = get_path_tables(region_of_interest)\n",
    "    \n",
    "    datasets_cut_fp = Datasets()\n",
    "    for index, dataset_fp in enumerate(datasets_counterparts):\n",
    "\n",
    "        flux_points= dataset_fp.data\n",
    "        try:\n",
    "            mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "            for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "                if e_ref >= e_ref_min:\n",
    "                    mask_energy[m] = True\n",
    "\n",
    "            flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "            flux_points_energy = FluxPoints.from_table(flux_points_mask)\n",
    "\n",
    "            ds = FluxPointsDataset(\n",
    "                models = datasets_counterparts[index].models[0],\n",
    "                data=flux_points_energy, \n",
    "                name = datasets_counterparts[index].name\n",
    "            )\n",
    "\n",
    "            datasets_cut_fp.append(ds)\n",
    "            table = ds.data.to_table(\n",
    "                sed_type = cfg.sed_type_e2dnde,\n",
    "                formatted = True\n",
    "            )    \n",
    "            file_name = name_to_txt(datasets_counterparts[index].name)            \n",
    "            write_tables_csv(table, path_tables, file_name)\n",
    "\n",
    "        except Exception as error:\n",
    "            print(f'The error ({dataset_fp.name}) is: {error}') \n",
    "    return datasets_cut_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf658db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickling_catalog_roi(catalogs_roi, region_of_interest):        \n",
    "    \n",
    "    # Creates the directory to save the list of catalogs roi  \n",
    "#     path_analysis, path_file = mkdir_sub_directory(cfg.dir_analysis, cfg.dir_catalogs_roi)\n",
    "    path_file = get_path_catalogs_roi()\n",
    "    \n",
    "    file_name = f\"catalog_{create_roi_name(region_of_interest['source_name'], region_of_interest['radius_roi'], region_of_interest['e_ref_min'])}\"\n",
    "    \n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_dat}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)       \n",
    "\n",
    "    with open(path_os, \"wb\") as fp:  \n",
    "        pickle.dump(catalogs_roi, fp)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "def unpickling_catalog_roi(region_of_interest):        \n",
    "    # Creates the directory to save the catalogs roi list  \n",
    "#     path_analysis, path_file = mkdir_sub_directory(cfg.dir_analysis, cfg.dir_catalogs_roi)\n",
    "    path_file = get_path_catalogs_roi()\n",
    "    file_name = f\"catalog_{create_roi_name(region_of_interest['source_name'], region_of_interest['radius_roi'], region_of_interest['e_ref_min'])}\"\n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_dat}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)       \n",
    "\n",
    "    with open(path_os, \"rb\") as fp:  \n",
    "        catalogs_roi = pickle.load(fp)\n",
    "    return catalogs_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1962a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_analysis():\n",
    "    return mkdir_sub_directory(cfg.dir_analysis)\n",
    "\n",
    "def get_path_catalogs_roi():\n",
    "    path_analysis, path_catalogs_roi = mkdir_sub_directory(str(get_path_analysis()), cfg.dir_catalogs_roi)\n",
    "    return path_catalogs_roi\n",
    "\n",
    "def get_path_datasets(region_of_interest):\n",
    "    path_analysis, path_datasets = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_datasets}/{region_of_interest['roi_name']}\" )\n",
    "    return path_datasets\n",
    "\n",
    "def get_path_models(region_of_interest):\n",
    "    path_analysis, path_models = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_models}/{region_of_interest['roi_name']}\")\n",
    "    return path_models\n",
    "\n",
    "def get_path_tables(region_of_interest = None):\n",
    "    if region_of_interest:\n",
    "        path_analysis, path_tables = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_tables}/{region_of_interest['roi_name']}\")\n",
    "    else:\n",
    "        path_analysis, path_tables = mkdir_sub_directory(str(get_path_analysis()), f\"{cfg.dir_tables}\")\n",
    "    return path_tables\n",
    "\n",
    "def get_path_figures():\n",
    "    path_analysis, path_figures = mkdir_sub_directory(str(get_path_analysis()), cfg.dir_figures)\n",
    "    return path_figures\n",
    "\n",
    "def get_path_SED_from_catalogs(region_of_interest):\n",
    "    path_figures, path_SED_from_catalogs = mkdir_sub_directory(str(get_path_figures()), f\"{cfg.dir_SED_from_catalogs}/{region_of_interest['roi_name']}\")\n",
    "    return path_SED_from_catalogs\n",
    "\n",
    "def get_path_SED():\n",
    "    path_figures, path_SED = mkdir_sub_directory(str(get_path_figures()), cfg.dir_SED)\n",
    "    return path_SED\n",
    "\n",
    "def get_path_flux_points():\n",
    "    path_figures, path_flux_points = mkdir_sub_directory(str(get_path_figures()), cfg.dir_flux_points)\n",
    "    return path_flux_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2a5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_sub_directory(parent_directory = None, child_directory = None):\n",
    "    '''Creates a directory: parent_directory/child_directory and returs the path \n",
    "    >>>mkdir_sub_directory(parent_directory, directory)\n",
    "    path_parent, path_child\n",
    "    '''\n",
    "    if child_directory is None:\n",
    "\n",
    "        path_parent = Path(f\"{parent_directory}\")\n",
    "        path_parent.mkdir(exist_ok=True)\n",
    "        print(\"Directory '% s' created\" % path_parent)\n",
    "        \n",
    "        return path_parent\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        path_parent = Path(f\"{parent_directory}\")\n",
    "        path_parent.mkdir(exist_ok=True)\n",
    "\n",
    "        path_child = Path(f\"{path_parent}/{child_directory}\")\n",
    "        path_child.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"Directory '% s' created\" % path_child)\n",
    "\n",
    "        return (path_parent, path_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_txt(name):\n",
    "    '''Given a `string`, `find` and `replace` the space by \"_\" and . by \"dot\"\n",
    "    >>> name_to_txt(n ame.)\n",
    "    namedot\n",
    "    '''\n",
    "    return name.replace(\" \", \"_\").replace(\".\", \"dot\").replace(\":\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96ef3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c50bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_txt(num):\n",
    "    '''Given a `number`, return a string\n",
    "    >>> number_to_txt(num = 1.002222):\n",
    "    1\n",
    "    '''\n",
    "    return (\"%.2f\" % num).rstrip('0').rstrip('.').replace(\".\", \"dot\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de1925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a1d7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.estimators import FluxPoints\n",
    "\n",
    "def ds_fp_from_table_fp(table, sky_model, source_name, sed_type = \"e2dnde\"):\n",
    "    '''Returns the flux points dataset from the flux points table \n",
    "    \n",
    "    >>> ds_fp_from_table_fp(table, sky_model, sed_type)\n",
    "    ds_fp\n",
    "    '''\n",
    "    flux_points = FluxPoints.from_table(table = table, reference_model = sky_model, sed_type=sed_type)\n",
    "    \n",
    "    ds_name = f'{source_name}'  \n",
    "    ds_fp = FluxPointsDataset(\n",
    "        models = sky_model,\n",
    "        data   = flux_points, \n",
    "        name   = ds_name\n",
    "    )\n",
    "    return ds_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def write_tables_csv(table, path_file, file_name):\n",
    "# Writes the flux points table in the csv format\n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_csv}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)\n",
    "\n",
    "    table.write(\n",
    "        f\"{path_os}\",\n",
    "        format = 'ascii.ecsv', \n",
    "        overwrite = True\n",
    "    )   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373eaa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def write_tables_fits(table, path_file, file_name):\n",
    "    # Writes the flux points table in the fits format\n",
    "    path_os = os.path.abspath(\n",
    "        os.path.join(\n",
    "            f\"{path_file}/{file_name}{cfg.format_fits}\"\n",
    "        )\n",
    "    )      \n",
    "\n",
    "    if path_os not in sys.path:\n",
    "        sys.path.append(path_os)\n",
    "\n",
    "    table.write(\n",
    "        f\"{path_os}\",\n",
    "        format = 'fits', \n",
    "        overwrite = True\n",
    "    )   \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5a331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
